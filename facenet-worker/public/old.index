<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Face Capture 160x160 Example</title>
    <!-- face-api.js (UMD/minified build) -->
    <script src="https://cdn.jsdelivr.net/npm/face-api.js/dist/face-api.min.js"></script>
    <style>
      body {
        font-family: monospace;
        margin: 15px;
      }
      video,
      canvas,
      img {
        display: block;
        margin: 1rem auto;
      }
      #croppedImage {
        border: 1px solid #ccc;
      }
    </style>
  </head>
  <body>
    <center>
    <h1>Capture and Crop a Face (160x160)</h1>

    <video id="video" width="640" height="480" autoplay muted></video>
    <button id="captureBtn">Capture</button>

    <p><strong>Cropped Image Preview (160×160):</strong></p>
    <img id="croppedImage" width="160" height="160" alt="Cropped Face will show here" />

    <div id="pick" width="250px"> </div>

    <script>
      // 1. Load face detection models
      async function loadModels() {
        await faceapi.nets.tinyFaceDetector.loadFromUri("/models");
        console.log("Models loaded");
      }

      // 2. Start the video stream
      async function startVideo() {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({
            video: true,
          });
          const videoElement = document.getElementById("video");
          videoElement.srcObject = stream;
        } catch (err) {
          console.error("Error accessing webcam: ", err);
          alert("Could not access webcam.");
        }
      }

      // 3. Capture the frame and detect a face
      async function captureAndDetectFace() {
        const videoElement = document.getElementById("video");

        // Create a temporary canvas to get the full video frame
        const fullCanvas = document.createElement("canvas");
        fullCanvas.width = videoElement.videoWidth;
        fullCanvas.height = videoElement.videoHeight;

        const fullCtx = fullCanvas.getContext("2d");
        fullCtx.drawImage(
          videoElement,
          0,
          0,
          fullCanvas.width,
          fullCanvas.height
        );

        // Detect a single face on that canvas
        const detection = await faceapi.detectSingleFace(
          fullCanvas,
          new faceapi.TinyFaceDetectorOptions()
        );

        if (!detection) {
          alert("No face detected. Please try again.");
          return;
        }

        // 4. Crop and resize the face to 160×160
        const { x, y, width, height } = detection.box;

        // Create a new canvas for the cropped/resized face
        const faceCanvas = document.createElement("canvas");
        const targetSize = 160; // Width & height of the final cropped image
        faceCanvas.width = targetSize;
        faceCanvas.height = targetSize;

        // Draw the face region from the fullCanvas onto the faceCanvas (scaled to 160x160)
        faceCanvas.getContext("2d").drawImage(
          fullCanvas,
          x, // source x
          y, // source y
          width, // source width
          height, // source height
          0, // destination x
          0, // destination y
          targetSize, // destination width
          targetSize // destination height
        );

        // 5. Display the 160×160 cropped face in the <img> element
        const dataUrl = faceCanvas.toDataURL("image/jpeg");
        document.getElementById("croppedImage").src = dataUrl;
        document.getElementById("pick").innerHTML = `
          <div style="display: flex; ">
            <button id="uploadBtn">Upload</button>
            <button id="matchBtn">Match</button>
          </div>
          <input id="name-input" />
        `;

        const blob = dataURLtoBlob(dataUrl);

        document
          .getElementById("uploadBtn")
          .addEventListener("click", async () => { 
            await uploadFace(blob)
            document.getElementById("pick").innerHTML = `Successfully uploaded! ✅`;
          });

        document
          .getElementById("matchBtn")
          .addEventListener("click", async () => { 
            const { name }  = await matchFace(blob)
            if (name) {
              document.getElementById("pick").innerHTML = `Matched! Greetings ${name}`;
            }
            document.getElementById("pick").innerHTML = `No match found :(`;
          });


        // 6. Send the image bytes (two options):
        //uploadCroppedFaceAsBlob(blob);
      }

      async function uploadFace(blob) {
        const name = document.getElementById('name-input').value.trim();
        if (!name) {
            alert('Enter a name pretty please.');
            return;
        }
        try {
          const embeddings = await computeFaceEmbeddings(blob);
          response = await fetch("http://localhost:65186/add", {
            method: "POST",
            body: JSON.stringify({
              name,
              picture: blob,
              embeddings: embeddings
            }),
          });
        } catch (err) {
          console.error("Error uploading blob:", err);
        }
      }

      // Convert a base64 string to a binary Blob
      function dataURLtoBlob(url) {
        const arr = url.split(",");
        const mime = arr[0].match(/:(.*?);/)[1];
        const bstr = atob(arr[1]);
        let n = bstr.length;
        const u8arr = new Uint8Array(n);
        while (n--) {
          u8arr[n] = bstr.charCodeAt(n);
        }
        return new Blob([u8arr], { type: mime });
      }

      async function computeFaceEmbeddings(blob) {
        try {
          let response = await fetch("/compute", {
            method: "POST",
            body: blob,
          });
          return await response.json();
        } catch (err) {
          console.error("Error computing embeddings:", err);
        }
      }

      async function matchFace(blob) {
        try {
          const embeddings = await computeFaceEmbeddings(blob);
          response = await fetch("http://localhost:65186/match", {
            method: "POST",
            body: JSON.stringify({
              embeddings: embeddings
            }),
          });
          return await response.json();
        } catch (err) {
          console.error("Error uploading blob:", err);
        }
      }

      // Main: Load models, start video, attach button listener
      window.addEventListener("load", async () => {
        await loadModels();
        await startVideo();

        document
          .getElementById("captureBtn")
          .addEventListener("click", captureAndDetectFace);
      });
    </script>
    </center>
  </body>
</html>
